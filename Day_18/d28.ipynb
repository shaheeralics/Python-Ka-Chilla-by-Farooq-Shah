{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the fashion mninst dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# load the training and test split of the fashion mnist dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fmnist) # it shows us the api of keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# you can put between 0 t0 59999 here \n",
    "index = 0 \n",
    "\n",
    "# set number of character p[er row when printing \n",
    "np.set_printoptions(linewidth = 320)\n",
    "\n",
    "# Print the lavvel and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'/nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(training_images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of the train and tes images (0-1) ranged\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the classification model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128,activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10,activation= tf.nn.softmax)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0,3.0,4.0,2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax fuction : {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation fuction\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'outputs of softmax fuction: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values agter the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with ghighest probability: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1500 - accuracy: 0.9434\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1438 - accuracy: 0.9461\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1430 - accuracy: 0.9466\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1378 - accuracy: 0.9480\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1349 - accuracy: 0.9499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9f74e2280>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4166 - accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4166051149368286, 0.8859999775886536]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on unseen data\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
